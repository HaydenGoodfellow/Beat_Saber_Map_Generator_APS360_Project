{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import string\r\n",
    "import json\r\n",
    "import pickle\r\n",
    "import zipfile\r\n",
    "import requests\r\n",
    "from io import BytesIO\r\n",
    "import time\r\n",
    "import timeit\r\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_song(download_url, song_name):\r\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36',\r\n",
    "               \"Upgrade-Insecure-Requests\": \"1\",\"DNT\": \"1\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\r\n",
    "               \"Accept-Language\": \"en-US,en;q=0.5\",\"Accept-Encoding\": \"gzip, deflate\"}\r\n",
    "    done = False\r\n",
    "    page_string = \"https://beatsaver.com{}\".format(download_url)\r\n",
    "    request_data = requests.get(page_string, headers=headers)\r\n",
    "\r\n",
    "    # Successfully got song data\r\n",
    "    if request_data.status_code == 200:\r\n",
    "        # Process data which is a zip file\r\n",
    "        data_zip = BytesIO(request_data.content)\r\n",
    "        valid_filename_chars = \"-_.() %s%s\" % (string.digits, string.ascii_letters)\r\n",
    "        out_filename = ''.join(char for char in song_name if char in valid_filename_chars)\r\n",
    "        out_filename = out_filename.replace(' ','_')\r\n",
    "        done = True\r\n",
    "        # Using a lazy try catch so I can let it run all night without it ending randomly due to some small error\r\n",
    "        try:\r\n",
    "            # We need to open a second zip files since you cant delete files from a zip file without extracting\r\n",
    "            with ZipFile(data_zip) as folder, ZipFile('Zip_Songs_Data/{}.zip'.format(out_filename), 'w') as out_zip:\r\n",
    "                filenames = folder.namelist()\r\n",
    "                # Get the key from the download url to do fast lookup in pandas df\r\n",
    "                key = download_url.rsplit('/', 1)[-1]\r\n",
    "                difficulties = (maps_df.loc[maps_df['key'] == key])['difficulty'].values\r\n",
    "\r\n",
    "                # If there is expertplus then we want to save the expertplus .dat file\r\n",
    "                if 'expertPlus' in difficulties:\r\n",
    "                    # Find any valid expert plus data file. re.I means ignore case\r\n",
    "                    ex_plus_files = list(filter(lambda x: re.match(r'((standard)*_?expert_?plus_?(standard)*\\.dat$)', x, flags=re.I), filenames)) \r\n",
    "                    if len(ex_plus_files) > 1: # Shouldn't happen\r\n",
    "                        print(\"More than one expert plus match. Fix your regex dumbass. Filenames: \", ex_plus_files)\r\n",
    "                    elif len(ex_plus_files) == 1:\r\n",
    "                        out_zip.writestr(ex_plus_files[0], folder.read(ex_plus_files[0]))\r\n",
    "                \r\n",
    "                # If there is expert then we want to save the expert .dat file\r\n",
    "                if 'expert' in difficulties:\r\n",
    "                    # Find any valid expert data file. re.I means ignore case\r\n",
    "                    expert_files = list(filter(lambda x: re.match(r'((standard)*_?expert_?(standard)*\\.dat$)', x, flags=re.I), filenames)) \r\n",
    "                    if len(expert_files) > 1: # Shouldn't happen\r\n",
    "                        print(\"More than one expert match. Fix your regex dumbass. Filenames: \", expert_files)\r\n",
    "                    elif len(expert_files) == 1:\r\n",
    "                        out_zip.writestr(expert_files[0], folder.read(expert_files[0]))\r\n",
    "\r\n",
    "                # Add any info.dat or metadata.dat files\r\n",
    "                info_files = list(filter(lambda x: re.match(r'(^(info|metadata)*\\.dat$)', x, flags=re.I), filenames)) \r\n",
    "                for info_file in info_files:\r\n",
    "                    out_zip.writestr(info_file, folder.read(info_file))\r\n",
    "\r\n",
    "                # Add cover image to output folder\r\n",
    "                cover_imgs = list(filter(lambda x: re.match(r'(cover\\.(jpg|png|jpeg)$)', x, flags=re.I), filenames)) \r\n",
    "                if len(cover_imgs) == 0: # Just add any png/jpg in the folder and call it cover\r\n",
    "                    cover_imgs = list(filter(lambda x: re.match(r'(.*\\.(jpg|png|jpeg))', x, flags=re.I), filenames)) \r\n",
    "                    # If there are no images in the song at all then use the default\r\n",
    "                    if len(cover_imgs) == 0:\r\n",
    "                        print(\"No cover image found in song {}. Filenames: \".format(song_name), filenames)\r\n",
    "                        out_zip.write(\"Zip_Songs_Data/cover.jpg\", \"cover.jpg\")\r\n",
    "                    else:\r\n",
    "                        out_zip.writestr(cover_imgs[0], folder.read(cover_imgs[0]))\r\n",
    "                # Want to just add the first image, dont care if there is more than 1\r\n",
    "                else:\r\n",
    "                    out_zip.writestr(cover_imgs[0], folder.read(cover_imgs[0]))\r\n",
    "\r\n",
    "                # Add song itself to output zip file\r\n",
    "                song_files = list(filter(lambda x: re.match(r'(^.+\\.(egg|ogg|mp4|mp3))', x, flags=re.I), filenames))\r\n",
    "                if len(song_files) == 0: # Very bad, no song found in folder\r\n",
    "                    print(\"No song file found in folder for song: {}. Filenames: \".format(song_name), filenames)\r\n",
    "                    out_zip.close()\r\n",
    "                    os.remove(out_zip.name)\r\n",
    "                    return done, 0\r\n",
    "                for song_file in song_files: # If multiple song files we'll deal with it in processing\r\n",
    "                    out_zip.writestr(song_file, folder.read(song_file))\r\n",
    "                \r\n",
    "                out_filenames = out_zip.namelist()\r\n",
    "                if sum('.dat' in f for f in out_filenames) <= 1:\r\n",
    "                    print(\"Don't have atleast two dat files for song: {}. Filenames: \".format(song_name), filenames)\r\n",
    "                    out_zip.close()\r\n",
    "                    os.remove(out_zip.name)\r\n",
    "                    return done, 0\r\n",
    "\r\n",
    "                # removed_files = list(set(filenames) ^ set(out_filenames))\r\n",
    "                # special_files = list(filter(lambda x: re.match(r'(?!easy|normal|hard).*', x, flags=re.I), removed_files))\r\n",
    "                # if len(special_files) >= 1:\r\n",
    "                #     print(\"Non-difficulty related files removed in song {}. Special files: \".format(song_name), special_files)\r\n",
    "                \r\n",
    "                return done, 0\r\n",
    "        except Exception as e:\r\n",
    "            print(\"Error {} occured when downloading song: {}. Total download count: {}\".format(e, song_name, total_download_count))\r\n",
    "            # Store the missed download in text file so we can download it later\r\n",
    "            with open('failed_download_nums.txt', 'a') as f:\r\n",
    "                f.write('{}, '.format(total_download_count))\r\n",
    "            # Delete the failed download zip's file\r\n",
    "            os.remove(\"Zip_Songs_Data/{}.zip\".format(out_filename))\r\n",
    "            return done, 5000\r\n",
    "    \r\n",
    "    # Timeout. Hit rate limit\r\n",
    "    elif request_data.status_code == 429: \r\n",
    "        print(\"Timeout. Status code:\", request_data.status_code, \"Timeout len:\", request_data.json()['resetAfter'])\r\n",
    "        return done, request_data.json()['resetAfter']\r\n",
    "    # Some other error\r\n",
    "    else:\r\n",
    "        done = True\r\n",
    "        print(\"Couldn't get song: {}. Status code: {}. Response: {}\".format(song_name, data.status_code, request_data.content))\r\n",
    "        return done, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_download_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_songs(maps_df, start_song=0, max_songs=50000):\r\n",
    "    print(\"Starting to download {} songs starting at song {}\".format(len(maps_df.download_URL.unique()), start_song))\r\n",
    "    global total_download_count\r\n",
    "    download_count = 0\r\n",
    "    start_time = time.time()\r\n",
    "    for download_url in maps_df.download_URL.unique():\r\n",
    "        if download_count > max_songs:\r\n",
    "            break\r\n",
    "        if download_count < start_song:\r\n",
    "            continue\r\n",
    "        if total_download_count % 50 == 0 and total_download_count != 0:\r\n",
    "            print(\"Downloaded up to song: \", total_download_count)\r\n",
    "        if total_download_count % 100 == 0 and total_download_count != 0:\r\n",
    "            curr_time = time.time()\r\n",
    "            print(\"Sleeping for 10 seconds to reset timeout timer. Time elasped: {:.2f}\".format(curr_time - start_time))\r\n",
    "            time.sleep(10)\r\n",
    "        # Get the song name using the key found in the download url\r\n",
    "        song_name = (maps_df.loc[maps_df['key'] == download_url.rsplit('/', 1)[-1]])['song_name'].values[0]\r\n",
    "        done = False\r\n",
    "        # Keep attempting to download if it keeps timing out\r\n",
    "        while not done:\r\n",
    "            done, timeout = download_song(download_url, song_name)\r\n",
    "            if timeout:\r\n",
    "                # Sleep to reset timeout\r\n",
    "                print(\"Sleeping for {} seconds to reset timeout timer\".format((timeout / 1000) + 1))\r\n",
    "                time.sleep((timeout / 1000) + 2)\r\n",
    "\r\n",
    "        download_count += 1\r\n",
    "        total_download_count += 1\r\n",
    "    end_time = time.time()\r\n",
    "    print(\"Time taken to download: {:.2f} seconds\".format(end_time - start_time))\r\n",
    "    print(\"Number of songs:\", download_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maps dataframe back from the pickle file\r\n",
    "maps_df = pd.read_pickle(\"maps_df.pkl\")\r\n",
    "\r\n",
    "# Download all the songs which get saved into .zip files in the Zip_Song_Data directory\r\n",
    "download_all_songs(maps_df, start_song=total_download_count, max_songs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'json', 'png', 'jpeg', 'dat', 'mp3', 'xmp', 'PNG', 'mp4', 'ogg', 'exe', 'sfk'}\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"D:\\Oculus\\Games\\Software\\hyperbolic-magnetism-beat-saber\\Beat Saber_Data\\CustomLevels\"\r\n",
    "names = {''}\r\n",
    "for subdir, dirs, files in os.walk(test_dir):\r\n",
    "    for file in files:\r\n",
    "        if not file.endswith(\".egg\") and not file.endswith(\".jpg\"):\r\n",
    "            names.add(file.rsplit('.', 1)[-1])\r\n",
    "\r\n",
    "print(names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "name": "python383jvsc74a57bd058c7c12f8aebb3b799780e2a952497b720e238e6f3ceeaa6cb2f46c86be22697"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}