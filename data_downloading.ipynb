{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import string\r\n",
    "import json\r\n",
    "import pickle\r\n",
    "import zipfile\r\n",
    "import requests\r\n",
    "from io import BytesIO\r\n",
    "import time\r\n",
    "import timeit\r\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_song(download_url, song_name, out_filename):\r\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36',\r\n",
    "               \"Upgrade-Insecure-Requests\": \"1\",\"DNT\": \"1\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\r\n",
    "               \"Accept-Language\": \"en-US,en;q=0.5\",\"Accept-Encoding\": \"gzip, deflate\"}\r\n",
    "    done, successful = False, False\r\n",
    "    page_string = \"https://beatsaver.com{}\".format(download_url)\r\n",
    "    request_data = requests.get(page_string, headers=headers)\r\n",
    "    requirements = []\r\n",
    "    # Successfully got song data\r\n",
    "    if request_data.status_code == 200:\r\n",
    "        # Process data which is a zip file\r\n",
    "        data_zip = BytesIO(request_data.content)\r\n",
    "        \r\n",
    "        # Get the key from the download url to do fast lookup in pandas df\r\n",
    "        key = download_url.rsplit('/', 1)[-1]\r\n",
    "        done = True\r\n",
    "        # Using a lazy try catch so I can let it run all night without it ending randomly due to some small error\r\n",
    "        try:\r\n",
    "            # Open a second zip and move the good files from the original to the new one\r\n",
    "            with ZipFile(data_zip) as folder, ZipFile('Zip_Songs_Data/{}.zip'.format(out_filename), 'w') as out_zip:\r\n",
    "                filenames = folder.namelist()\r\n",
    "                # Difficulties which have met our criteria\r\n",
    "                difficulties = (maps_df.loc[maps_df['key'] == key])['difficulty'].values\r\n",
    "                difficulties = [(diff[0].upper() + diff[1:]) for diff in difficulties]\r\n",
    "                if \"ExpertPlus\" in difficulties:\r\n",
    "                    difficulties = np.append(difficulties, \"Expert+\") # Old naming convention\r\n",
    "\r\n",
    "                # Find info.dat file        \r\n",
    "                info_files = list(filter(lambda x: re.match(r'(^(info)*\\.dat$)', x, flags=re.I), filenames)) \r\n",
    "                if len(info_files) == 0:\r\n",
    "                    raise Exception(\"No info.dat file found. Filenames: {}\".format(filenames))\r\n",
    "                \r\n",
    "                # Add info.dat file and any difficulty .dat files which are in acceptable difficulties\r\n",
    "                num_diff_dats = 0\r\n",
    "                for info_file_zip in info_files: # Should only be one info file\r\n",
    "                    out_zip.writestr(info_file_zip, folder.read(info_file_zip))\r\n",
    "                    with folder.open(info_file_zip) as info_file:\r\n",
    "                        info_json = json.load(info_file)\r\n",
    "                        diff_sets = info_json['_difficultyBeatmapSets']\r\n",
    "                        # Difficulty sets based on game type.. Only care about standard\r\n",
    "                        for diff_set in diff_sets: \r\n",
    "                            if diff_set['_beatmapCharacteristicName'] != \"Standard\":\r\n",
    "                                continue\r\n",
    "                            beatmap_diffs = diff_set['_difficultyBeatmaps']\r\n",
    "                            # Beatmaps based on difficulty in standard mode\r\n",
    "                            for beatmap_diff in beatmap_diffs:\r\n",
    "                                # If this difficulty map meets the criteria used in data filtering\r\n",
    "                                if beatmap_diff['_difficulty'] in difficulties:\r\n",
    "                                    diff_dat_file = beatmap_diff['_beatmapFilename']\r\n",
    "                                    if diff_dat_file not in filenames: # Should never happen\r\n",
    "                                        raise Exception(\"Diff dat file not found in filenames: {}. Filenames: {}\".format(diff_dat_file, filenames))\r\n",
    "                                    # Standardize the names of .dat for ease of use. Prevents names like hell.dat for expert+ ruining the data\r\n",
    "                                    dat_file_name = \"Expert.dat\"\r\n",
    "                                    if beatmap_diff['_difficulty'] == \"ExpertPlus\" or beatmap_diff['_difficulty'] == \"Expert+\":\r\n",
    "                                        dat_file_name = \"ExpertPlus.dat\"\r\n",
    "                                    out_zip.writestr(dat_file_name, folder.read(diff_dat_file))\r\n",
    "                                    num_diff_dats += 1\r\n",
    "                                    # Add the requirements to the dataframe\r\n",
    "                                    try:\r\n",
    "                                        if len(beatmap_diff['_customData']['_requirements']) >= 1:\r\n",
    "                                            requirements.append(beatmap_diff['_customData']['_requirements'])\r\n",
    "                                            # print(\"Song {} has the following requirements: {}\".format(song_name, requirements))\r\n",
    "                                    except KeyError as ke: # Some songs don't have a requirements or customdata\r\n",
    "                                        continue\r\n",
    "\r\n",
    "\r\n",
    "                if num_diff_dats <= 0:\r\n",
    "                    raise Exception(\"No suitable difficulty dat files found.\\nFilenames: {}.\\nDifficulties: {}\".format(filenames, difficulties))\r\n",
    "                \r\n",
    "                # Add cover image to output folder\r\n",
    "                cover_imgs = list(filter(lambda x: re.match(r'(cover\\.(jpg|png|jpeg)$)', x, flags=re.I), filenames)) \r\n",
    "                if len(cover_imgs) == 0: # Just add any png/jpg in the folder and call it cover\r\n",
    "                    cover_imgs = list(filter(lambda x: re.match(r'(.*\\.(jpg|png|jpeg))', x, flags=re.I), filenames)) \r\n",
    "                    # If there are no images in the song at all then use the default\r\n",
    "                    if len(cover_imgs) == 0:\r\n",
    "                        print(\"No cover image found in song {}. Filenames: \".format(song_name), filenames)\r\n",
    "                        out_zip.write(\"Zip_Songs_Data/cover.jpg\", \"cover.jpg\")\r\n",
    "                    else:\r\n",
    "                        out_zip.writestr(cover_imgs[0], folder.read(cover_imgs[0]))\r\n",
    "                # Want to just add the first image, dont care if there is more than 1\r\n",
    "                else:\r\n",
    "                    out_zip.writestr(cover_imgs[0], folder.read(cover_imgs[0]))\r\n",
    "\r\n",
    "                # Add song itself to output zip file\r\n",
    "                song_files = list(filter(lambda x: re.match(r'(^.+\\.(egg|ogg|mp4|mp3))', x, flags=re.I), filenames))\r\n",
    "                if len(song_files) == 0: # Very bad, no song found in folder\r\n",
    "                    out_zip.close()\r\n",
    "                    raise Exception(\"No song file found in folder for song: {}. Filenames: {}\".format(song_name, filenames))\r\n",
    "                for song_file in song_files: # If multiple song files we'll deal with it in processing\r\n",
    "                    out_zip.writestr(song_file, folder.read(song_file))\r\n",
    "                \r\n",
    "                # Make sure we have atleast one info.dat and one difficulty.dat\r\n",
    "                out_filenames = out_zip.namelist()\r\n",
    "                if sum('.dat' in f for f in out_filenames) <= 1:\r\n",
    "                    out_zip.close()\r\n",
    "                    raise Exception(\"Don't have atleast two dat files for song: {}. Filenames: {}\".format(song_name, filenames))\r\n",
    "                \r\n",
    "                successful = True\r\n",
    "                return done, successful, requirements, 0\r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "            print(\"Error {} occured when downloading song: {}. Key: {}. Total download count: {}\".format(e, song_name, key, total_download_count))\r\n",
    "            # Store the missed download in text file so we can download it later\r\n",
    "            with open('failed_download_nums.txt', 'a') as f:\r\n",
    "                f.write('(Num: {}, Key: {}), '.format(total_download_count, key))\r\n",
    "            # Delete the failed download zip's file\r\n",
    "            os.remove('Zip_Songs_Data/{}.zip'.format(out_filename))\r\n",
    "            return done, successful, requirements, 5000\r\n",
    "    \r\n",
    "    # Timeout. Hit rate limit\r\n",
    "    elif request_data.status_code == 429: \r\n",
    "        print(\"Timeout. Status code:\", request_data.status_code, \"Timeout len:\", request_data.json()['resetAfter'])\r\n",
    "        return done, successful, requirements, request_data.json()['resetAfter']\r\n",
    "    # Some other error\r\n",
    "    else:\r\n",
    "        done = True\r\n",
    "        print(\"Couldn't get song: {}. Status code: {}. Response: {}\".format(song_name, request_data.status_code, request_data.content))\r\n",
    "        return done, successful, requirements, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_songs(maps_df, start_song=0, max_songs=50000):\r\n",
    "    print(\"Starting to download {} songs starting at song {}\".format(min(len(maps_df.download_URL.unique()), max_songs), start_song))\r\n",
    "    global total_download_count\r\n",
    "    download_count = 0\r\n",
    "    start_count = 0\r\n",
    "\r\n",
    "    start_time = time.time()\r\n",
    "    for download_url in maps_df.download_URL.unique():\r\n",
    "        if download_count > max_songs:\r\n",
    "            break\r\n",
    "        if start_count < start_song:\r\n",
    "            start_count += 1\r\n",
    "            continue\r\n",
    "        if total_download_count % 50 == 0 and total_download_count != 0:\r\n",
    "            print(\"Downloaded up to song: \", total_download_count)\r\n",
    "        if download_count % 1000 == 0 and download_count != 0:\r\n",
    "            curr_time = time.time()\r\n",
    "            print(\"Sleeping for 60 seconds to reset timeout timer. Time elasped: {:.2f}\".format(curr_time - start_time))\r\n",
    "            time.sleep(60)\r\n",
    "\r\n",
    "        # Get the song name using the key found in the download url\r\n",
    "        key = download_url.rsplit('/', 1)[-1]\r\n",
    "        song_name = (maps_df.loc[maps_df['key'] == key])['song_name'].values[0] # Key is unique so only one value\r\n",
    "        # Determine acceptable file name given the song name\r\n",
    "        valid_filename_chars = \"-_.() %s%s\" % (string.digits, string.ascii_letters)\r\n",
    "        valid_filename = ''.join(char for char in song_name if char in valid_filename_chars)\r\n",
    "        valid_filename = valid_filename.replace(' ','_')\r\n",
    "        out_filename = \"({})_{}\".format(key, valid_filename)\r\n",
    "\r\n",
    "        done = False\r\n",
    "        successful = False\r\n",
    "        # Keep attempting to download if it keeps timing out\r\n",
    "        while not done:\r\n",
    "            done, successful, requirements, timeout = download_song(download_url, song_name, out_filename)\r\n",
    "            if timeout:\r\n",
    "                # Sleep to reset timeout\r\n",
    "                print(\"Sleeping for {} seconds to reset timeout timer\".format((timeout / 1000) + 1))\r\n",
    "                time.sleep((timeout / 1000) + 2)\r\n",
    "        \r\n",
    "        # Add path to file if successful\r\n",
    "        if successful:\r\n",
    "            maps_df.loc[maps_df['key'] == key, 'file_path'] = 'Zip_Songs_Data/{}.zip'.format(out_filename)\r\n",
    "            if len(requirements) >= 1:\r\n",
    "                maps_df.loc[maps_df['key'] == key, 'requirements'] = ' '.join([str(req) for req in requirements])\r\n",
    "        download_count += 1\r\n",
    "        total_download_count += 1\r\n",
    "    end_time = time.time()\r\n",
    "    print(\"Time taken to download: {:.2f} seconds\".format(end_time - start_time))\r\n",
    "    print(\"Number of songs:\", download_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maps dataframe back from the pickle file\r\n",
    "maps_df = pd.read_pickle(\"maps_df.pkl\")\r\n",
    "\r\n",
    "# Global variable which keeps track of number of sounds downloaded so far\r\n",
    "total_download_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the songs which get saved into .zip files in the Zip_Song_Data directory\r\n",
    "download_all_songs(maps_df, start_song=total_download_count, max_songs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN AFTER YOU'VE DOWNLOADED ALL SONGS YOU WANT\r\n",
    "maps_df = maps_df[maps_df['file_path'] != \"NOT_FOUND\"]\r\n",
    "\r\n",
    "# Save the updated dataframe in its pickle file\r\n",
    "maps_df.to_pickle(\"downloaded_maps_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataframe to store the path of the song's zip file or delete from dataframe if not found\r\n",
    "def add_key_to_file_name(maps_df): # This is a fix for a mistake. I shouldve done this from the start\r\n",
    "    count = 0\r\n",
    "    opt = []\r\n",
    "    \r\n",
    "    for subdir, dirs, files in os.walk('Zip_Songs_Data'):\r\n",
    "        for file in files:\r\n",
    "            # try:\r\n",
    "            with ZipFile('Zip_Songs_Data/{}'.format(file)) as folder:\r\n",
    "                # folder.printdir()\r\n",
    "                filenames = folder.namelist()\r\n",
    "                info_files = list(filter(lambda x: re.match(r'(^(info)*\\.dat$)', x, flags=re.I), filenames)) \r\n",
    "                for info_file in info_files:\r\n",
    "                    with folder.open(info_file) as f:\r\n",
    "                        # try:\r\n",
    "                        file_json = json.load(f)\r\n",
    "                        # print(json.dumps(file_json, indent=2))\r\n",
    "                        diff_sets = file_json['_difficultyBeatmapSets']\r\n",
    "                        for diff_set in diff_sets:\r\n",
    "                            if diff_set['_beatmapCharacteristicName'] != \"Standard\":\r\n",
    "                                continue\r\n",
    "                            diff_beatmaps = diff_set['_difficultyBeatmaps']\r\n",
    "                            for diff_beatmap in diff_beatmaps:\r\n",
    "                                print(diff_beatmap)\r\n",
    "                                print(diff_beatmap['_customData']['_requirements'])\r\n",
    "                                print(diff_beatmap['_difficulty'])\r\n",
    "                                # opt.append(diff_beatmap['_difficulty'])\r\n",
    "                                # requirements.append(diff_beatmap['_requirements'])\r\n",
    "                        count += 1\r\n",
    "                        # except Exception as e:\r\n",
    "                        #     print(\"{}. Couldn't open {} as JSON in file {}\".format(e, info_file, file))\r\n",
    "                        #     break\r\n",
    "            # except:\r\n",
    "            #     continue\r\n",
    "    \r\n",
    "    # print(set(opt))\r\n",
    "    # print(set(requirements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'json', 'png', 'jpeg', 'dat', 'mp3', 'xmp', 'PNG', 'mp4', 'ogg', 'exe', 'sfk'}\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"D:\\Oculus\\Games\\Software\\hyperbolic-magnetism-beat-saber\\Beat Saber_Data\\CustomLevels\"\r\n",
    "names = {''}\r\n",
    "for subdir, dirs, files in os.walk(test_dir):\r\n",
    "    for file in files:\r\n",
    "        if not file.endswith(\".egg\") and not file.endswith(\".jpg\"):\r\n",
    "            names.add(file.rsplit('.', 1)[-1])\r\n",
    "\r\n",
    "print(names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "name": "python383jvsc74a57bd058c7c12f8aebb3b799780e2a952497b720e238e6f3ceeaa6cb2f46c86be22697"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}