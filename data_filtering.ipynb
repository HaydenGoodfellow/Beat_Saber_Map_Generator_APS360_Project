{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "import pickle\r\n",
    "import requests\r\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model is for L33T gamers only so we will remove all songs that are not expert or expert+\r\n",
    "def remove_below_expert_songs(maps_data):\r\n",
    "    del_count = 0\r\n",
    "    for i in range(len(maps_data) - 1, -1, -1):\r\n",
    "        song_map = maps_data[i]\r\n",
    "        song_difficulties = song_map['metadata']['difficulties']\r\n",
    "        if song_difficulties['expert'] != True and song_difficulties['expertPlus'] != True:\r\n",
    "            del maps_data[i]\r\n",
    "            del_count += 1\r\n",
    "    print(\"Removed {} maps which didn't have expert or expert+ difficulty\".format(del_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lowly rated songs to have our model output ones which are considered higher quality\r\n",
    "def remove_low_rated_songs(maps_data, min_rating=0.6):\r\n",
    "    del_count = 0\r\n",
    "    for i in range(len(maps_data) - 1, -1, -1):\r\n",
    "        song_map = maps_data[i]\r\n",
    "        song_stats = song_map['stats']\r\n",
    "        rating = song_stats['rating']\r\n",
    "        if rating < min_rating:\r\n",
    "            del maps_data[i]\r\n",
    "            del_count += 1\r\n",
    "        #     print(\"Upvotes: {}. Downvotes: {}. Rating: {}\".format(song_stats['upVotes'], song_stats['downVotes'], song_stats['rating']))\r\n",
    "    print(\"Removed {} maps which didn't reach a rating of atleast {}\".format(del_count, min_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove maps that are only for the non-standard game modes (such as one saber mode or darth maul mode)\r\n",
    "def remove_non_standard_songs(maps_data):\r\n",
    "    song_del_count = 0\r\n",
    "    for i in range(len(maps_data) - 1, -1, -1):\r\n",
    "        song_map = maps_data[i]\r\n",
    "        characteristics = song_map['metadata']['characteristics']\r\n",
    "\r\n",
    "        # Remove non-standard modes from the table\r\n",
    "        del_indicies = [] # Indicies of the non-standard mode versions\r\n",
    "        for j, mode_type in enumerate(characteristics):\r\n",
    "            if not mode_type['name'] == \"Standard\":\r\n",
    "                del_indicies.append(j)\r\n",
    "\r\n",
    "        if len(del_indicies) != 0:\r\n",
    "            # Doing this to avoid errors in the case where there is more than one non-standard mode\r\n",
    "            # and it deleted the wrong element because the j index is off on the second delete \r\n",
    "            characteristics = np.delete(characteristics, del_indicies).tolist()\r\n",
    "            \r\n",
    "            if len(characteristics) not in [0, 1]:\r\n",
    "                print(\"Length not in 0 or 1. Length:\", len(characteristics), \"i:\", i)\r\n",
    "                for name in characteristics:\r\n",
    "                    print(name['name'])\r\n",
    "        \r\n",
    "        # If there are no more types then there is no standard mode version so delete\r\n",
    "        if len(characteristics) == 0:\r\n",
    "            del maps_data[i]\r\n",
    "            song_del_count += 1\r\n",
    "        \r\n",
    "        else:\r\n",
    "            assert (characteristics[0])['name'] == \"Standard\"\r\n",
    "\r\n",
    "        song_map['metadata']['characteristics'] = characteristics\r\n",
    "\r\n",
    "    print(\"Removed {} maps which didn't have a standard mode version\".format(song_del_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most short songs (below 30 sec) are usually \"meme\" maps with weird patterns which we want to ignore, such as the fortnite dance map\r\n",
    "# Similarly, most long songs (over 10 minutes) are also \"meme\" maps, such as the entire Shrek movie map  \r\n",
    "def remove_short_or_long_songs(maps_data, duration_lower_bound=20, duration_upper_bound=600):\r\n",
    "    short_del_count, long_del_count = 0, 0\r\n",
    "    for i in range(len(maps_data) - 1, -1, -1):\r\n",
    "        song_map = maps_data[i]\r\n",
    "        if len(song_map['metadata']['characteristics']) != 0:\r\n",
    "            characteristics = song_map['metadata']['characteristics'][0]\r\n",
    "            # If remove_non_standard_songs is working this should never happen\r\n",
    "            if characteristics['name'] != \"Standard\":\r\n",
    "                print(\"Non-standard mode found. i:\", i, \"mode name:\", characteristics['name'])\r\n",
    "            for difficulty, data in characteristics['difficulties'].items():\r\n",
    "                # Check if this map has a version for this difficulty\r\n",
    "                if data != None:\r\n",
    "                    # We only need to check one difficulty as the song length is the same accross difficulties\r\n",
    "                    if data['length'] < duration_lower_bound:\r\n",
    "                        del maps_data[i]\r\n",
    "                        short_del_count += 1\r\n",
    "                    elif data['length'] > duration_upper_bound:\r\n",
    "                        del maps_data[i]\r\n",
    "                        long_del_count += 1\r\n",
    "                    break\r\n",
    "    \r\n",
    "    print(\"Removed {} maps which were too short and {} maps which were too long\".format(short_del_count, long_del_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the important info for each map from the data so we can analyze it and easily remove outliers\r\n",
    "def convert_to_pandas(maps_data, lower_nps_quantile=0.03, upper_nps_quantile=0.995, upper_bombs_quantile=0.97):\r\n",
    "    # Extract the important values for each map into a dictonary stored in a list for pandas\r\n",
    "    list_of_vals = []\r\n",
    "    for i, song_map in enumerate(maps_data):\r\n",
    "        characteristics = song_map['metadata']['characteristics'][0]\r\n",
    "        for difficulty, data in characteristics['difficulties'].items():\r\n",
    "            # Check if this map has a version for this difficulty\r\n",
    "            if data != None:\r\n",
    "                if difficulty == \"expert\" or difficulty == \"expertPlus\":\r\n",
    "                    # print(data['bpm'])\r\n",
    "                    list_of_vals.append({'song_name' : song_map['name'],\r\n",
    "                                         'key' : song_map['key'],\r\n",
    "                                         'download_URL' : song_map['downloadURL'],\r\n",
    "                                         'difficulty' : difficulty,\r\n",
    "                                         'rating' : song_map['stats']['rating'],\r\n",
    "                                         'notes' : data['notes'],\r\n",
    "                                         'bombs' : data['bombs'],\r\n",
    "                                         'length' : data['length'],\r\n",
    "                                         'njs' : data['njs']\r\n",
    "                                         })\r\n",
    "    \r\n",
    "    # Use the list to make the pandas dataframe\r\n",
    "    maps_df = pd.DataFrame(list_of_vals)\r\n",
    "\r\n",
    "    # Use the dataframe to remove invalid maps (for some reason there are a few maps with no notes)\r\n",
    "    zero_val_row = pd.concat([maps_df[cols] == 0 for cols in ['notes', 'length']], axis=1).any(axis=1)\r\n",
    "    maps_df = maps_df[~zero_val_row]\r\n",
    "    print(\"Removed {} maps which had values set at either zero notes or zero length\".format(zero_val_row.value_counts().loc[True]))\r\n",
    "    # Make sure none of our songs are invalid\r\n",
    "    assert ((maps_df['notes'].values == 0).sum()) == 0\r\n",
    "    assert ((maps_df['length'].values == 0).sum()) == 0\r\n",
    "\r\n",
    "    # Use the dataframe to remove outliers in terms of number of notes per second\r\n",
    "    # We use notes per second because our song duration varies greatly so a short song may notes in the 1st quantile but still be good \r\n",
    "    maps_df['nps'] = maps_df['notes'] / maps_df['length']\r\n",
    "    lower_nps_cutoff = maps_df['nps'].quantile(lower_nps_quantile) # Should remove most 'light show'/'wall art' maps that weren't tagged or exetremely easy maps (our model is for l33t gamers only)\r\n",
    "    upper_nps_cutoff = maps_df['nps'].quantile(upper_nps_quantile) # We want our model to make hard songs, just not exetremely hard ones\r\n",
    "    # print(\"Lower notes per second cutoff: {}. Upper notes per second cutoff: {}.\".format(lower_nps_cutoff, upper_nps_cutoff))\r\n",
    "    \r\n",
    "    # Use the dataframe to remove upper outliers in number of bombs\r\n",
    "    # We do this to remove the 'dance' maps which use mostly bombs and walls to force the player to move in a certain way \r\n",
    "    upper_bombs_cutoff = maps_df['bombs'].quantile(upper_bombs_quantile) # No lower cutoff because we dont care if a map has no bombs\r\n",
    "    # print(\"Upper bombs cutoff: {}.\".format(upper_bombs_cutoff))\r\n",
    "\r\n",
    "    size_before_removing_outliers = len(maps_df)\r\n",
    "    maps_df = maps_df[(maps_df['nps'] >= lower_nps_cutoff) \r\n",
    "                     &(maps_df['nps'] <= upper_nps_cutoff)\r\n",
    "                     &(maps_df['bombs'] <= upper_bombs_cutoff)]\r\n",
    "    print(\"Removed {} maps which were outliers in terms of number of notes per second or bombs\".format(size_before_removing_outliers - len(maps_df)))\r\n",
    "\r\n",
    "    return maps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs originally: 40875\n",
      "Removed 6220 maps which didn't have expert or expert+ difficulty\n",
      "Number of songs after removing ones without expert or expert+: 34655\n",
      "Removed 8084 maps which didn't reach a rating of atleast 0.54\n",
      "Number of songs after removing low rated ones: 26571\n",
      "Removed 101 maps which didn't have a standard mode version\n",
      "Number of songs after removing ones without a standard mode version: 26470\n",
      "Removed 1117 maps which were too short and 105 maps which were too long\n",
      "Number of songs after removing ones that are too short or too long: 25248\n",
      "Removed 10 maps which had values set at either zero notes or zero length\n",
      "Removed 1908 maps which were outliers in terms of number of notes per second or bombs\n",
      "Number of maps (seperated by difficulty) after removing invalid ones and outliers in notes per second or bombs: 28593\n"
     ]
    }
   ],
   "source": [
    "with open(\"maps_data.json\", 'r') as f:\r\n",
    "    maps_data = json.load(f)\r\n",
    "\r\n",
    "#======================== Removal Settings ========================#\r\n",
    "min_rating = 0.54           # Ratio of upvotes to downvotes\r\n",
    "duration_lower_bound = 20   # Seconds\r\n",
    "duration_upper_bound = 600  # Seconds\r\n",
    "lower_nps_quantile = 0.03   # Quantile\r\n",
    "upper_nps_quantile = 0.995  # Quantile\r\n",
    "upper_bombs_quantile = 0.97 # Quantile\r\n",
    "#==================================================================#\r\n",
    "\r\n",
    "print(\"Number of songs originally:\", len(maps_data))\r\n",
    "\r\n",
    "remove_below_expert_songs(maps_data)\r\n",
    "print(\"Number of songs after removing ones without expert or expert+:\", len(maps_data))\r\n",
    "\r\n",
    "remove_low_rated_songs(maps_data, min_rating=min_rating)\r\n",
    "print(\"Number of songs after removing low rated ones:\", len(maps_data))\r\n",
    "\r\n",
    "remove_non_standard_songs(maps_data)\r\n",
    "print(\"Number of songs after removing ones without a standard mode version:\", len(maps_data))\r\n",
    "\r\n",
    "remove_short_or_long_songs(maps_data, duration_lower_bound=duration_lower_bound, duration_upper_bound=duration_upper_bound)\r\n",
    "print(\"Number of songs after removing ones that are too short or too long:\", len(maps_data))\r\n",
    "\r\n",
    "maps_df = convert_to_pandas(maps_data, lower_nps_quantile=lower_nps_quantile, upper_nps_quantile=upper_nps_quantile, upper_bombs_quantile=upper_bombs_quantile)\r\n",
    "print(\"Number of maps (seperated by difficulty) after removing invalid ones and outliers in notes per second or bombs:\", len(maps_df))\r\n",
    "\r\n",
    "# Save the dataframe in a pickle file\r\n",
    "maps_df.to_pickle(\"maps_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(maps_data[463]['metadata']['characteristics']))\r\n",
    "print(len(maps_data[463]['metadata']['characteristics']))\r\n",
    "print(maps_data[463].keys())\r\n",
    "print(maps_data[463]['metadata'].keys())\r\n",
    "print(maps_data[463]['metadata']['characteristics'][0]['difficulties'].values())\r\n",
    "print(json.dumps(maps_data[33]['metadata']['difficulties'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "name": "python383jvsc74a57bd058c7c12f8aebb3b799780e2a952497b720e238e6f3ceeaa6cb2f46c86be22697"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}